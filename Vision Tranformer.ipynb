{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce82c48-b639-4c67-933f-ea079c7183e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120dfd12-e923-4efe-8b5b-aaebe5ded7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 1\n",
    "input_shape = (130, 130, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28547f3e-751c-4fe0-9329-e0906f4864f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "weight_decay = 0.0001\n",
    "batch_size = 256\n",
    "num_epochs = 100  # For real training, use num_epochs=100. 10 is a test value\n",
    "image_size = 130  # We'll resize input images to this size\n",
    "patch_size = 6  # Size of the patches to be extract from the input images\n",
    "num_patches = (image_size // patch_size) ** 2\n",
    "projection_dim = 64\n",
    "num_heads = 4\n",
    "transformer_units = [\n",
    "    projection_dim * 2,\n",
    "    projection_dim,\n",
    "]  # Size of the transformer layers\n",
    "transformer_layers = 8\n",
    "mlp_head_units = [\n",
    "    2048,\n",
    "    1024,\n",
    "]  # Size of the dense layers of the final classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e2e273-276b-4d59-9391-5e1d8d9c7fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([ \n",
    "  tf.keras.layers.RandomFlip('horizontal_and_vertical'),\n",
    "  tf.keras.layers.RandomRotation(0.2),\n",
    "  tf.keras.layers.RandomBrightness(factor=0.2),\n",
    "  tf.keras.layers.RandomContrast(factor=0.2),\n",
    "  tf.keras.layers.Rescaling(scale=1./255),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf21f13-e2a2-4f70-b217-ffefe0a7e1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(x, hidden_units, dropout_rate):\n",
    "    for units in hidden_units:\n",
    "        x = tf.keras.layers.Dense(units, activation=keras.activations.gelu)(x)\n",
    "        x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09d1d0a-dc2b-4e13-85e8-66d82ec41b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Patches(tf.keras.layers.Layer):\n",
    "    def __init__(self,patch_size):\n",
    "        super().__init__()\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "\n",
    "    def call(self,images):\n",
    "        input_shape = tf.shape(images)\n",
    "        batch_size = input_shape[0]\n",
    "        height = input_shape[1]\n",
    "        width = input_shape[2]\n",
    "        channels = input_shape[3]\n",
    "        # Floor division\n",
    "        num_vertical_patches = height // self.patch_size\n",
    "        num_horizontal_patches = width // self.pathc_size\n",
    "        total_patches = num_vertical_patches * num_horizontal_patches\n",
    "        # Creating the patches\n",
    "        patches = tf.image.extract_patches(images,size=[1,self.patch_size,self.patch_size,1])\n",
    "        patches = tf.reshape(patches,[batch_size,total_patches,self.patch_size*self.patch_size*channels])\n",
    "        return patches\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\"patch_size\":self.patch_size})\n",
    "        return config\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4719d89d-7f56-4670-a86f-835bd978a370",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchEncoder(tf.keras.layers.Layer):\n",
    "    def __init__(self,num_patches,projection_dim):\n",
    "        super().__init__()\n",
    "        self.num_patches = num_patches\n",
    "        self.projection = layers.Dense(units=projection_dim)\n",
    "        self.position_embedding = layers.Embedding(\n",
    "            input_dim = num_patches, output_dim=projection_dim\n",
    "        )\n",
    "\n",
    "\n",
    "    def call(self,patch):\n",
    "        positions = tf.expand_dims(\n",
    "            tf.keras.ops.arange(0,self.num_patches,1), axis=0\n",
    "        )\n",
    "        projected_patches = self.projection(patch)\n",
    "        encoded = projected_patches + self.position_embedding(positions)\n",
    "        return encoded\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\"num_patches\": self.num_patches})\n",
    "        return config\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a802d2-0e66-4920-a9a7-90ee32c9aca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vit():\n",
    "    inputs = tf.keras.Input((130,130,3))\n",
    "    augmentation = data_augmentation(inputs)\n",
    "    patches = Patches(patch_size)(augmentation)\n",
    "    encoded_patches = PatchEncoder(num_patches,projection_dim)(patches)\n",
    "    for _ in range(transformer_layers):\n",
    "        x1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "        attention_output = tf.keras.layers.MultiHeadAttention(num_heads=num_heads,key_dim=projection_dim,dropout=0.1)(x1,x1)\n",
    "        x2 = tf.keras.layers.Add()([attention_output,encoded_patches])\n",
    "        x3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "        # MLP.\n",
    "        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n",
    "        # Skip connection 2.\n",
    "        encoded_patches = tf.keras.layers.Add()([x3, x2])\n",
    "    \n",
    "    representation = tf.keras.layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "    representation = tf.keras.layers.Flatten()(representation)\n",
    "    representation = tf.keras.layers.Dropout(0.5)(representation)\n",
    "    # Add MLP.\n",
    "    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n",
    "    # Classify outputs.\n",
    "    logits = tf.keras.layers.Dense(num_classes)(features)\n",
    "    # Create the Keras model.\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=logits)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a7d11c-b015-4228-9955-da0b144a3531",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_vit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a90d75-f403-4484-bc0d-dd790d6478b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
